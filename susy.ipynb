{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema de classificação de partículas exóticas (SUSY)\n",
    "\n",
    "O dataset contém 5 milhões de amostras de simulações. A classe é indicada na primeira coluna (0 ou 1); as 8 colunas seguintes são features obtidas originalmente das simulações, e as 10 seguintes são features de alto nível, computadas a partir das anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 19)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = [\"class\", \"lepton 1 pT\", \"lepton 1 eta\", \"lepton 1 phi\", \"lepton 2 pT\", \"lepton 2 eta\", \n",
    "         \"lepton 2 phi\", \"missing energy magnitude\", \"missing energy phi\", \"MET_rel\",\n",
    "         \"axial MET\", \"M_R\", \"M_TR_2\", \"R\", \"MT2\", \"S_R\", \"M_Delta_R\", \"dPhi_r_b\", \"cos(theta_r1)\"\n",
    "        ]\n",
    "data = pd.read_csv(\"SUSY.csv\", names=names, nrows=10000)\n",
    "print(data.shape)\n",
    "\n",
    "array = data.values\n",
    "X = array[:, 1:]\n",
    "Y = array[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: https://machinelearningmastery.com/an-introduction-to-feature-selection/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de correlação\n",
    "\n",
    "[Documentação](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr)\n",
    "\n",
    "Como indicado pelo nome, comporta a correlação entre os dados. No geral, é preciso indicar um método de cálculo do coeficiente( pearson - Coeficiente de correlação padrão, kendall, spearman), em caso de omissão, como abaixo utiliza-se o método padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c0051b9b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAD1hJREFUeJzt3Xts3fV5x/HPYzsJMSYJl5iExeGatCtCS4uFVEEh7ZbCKjroVNAYFaARJSvLQGL/8MdYgVGBtBU61kELIgqauJRKo4VBuYxeUlhLG0ZWgrYQLqG5gUMgJM6JSXz87A8OjzIS4+9j+5zj2O+XFB375PHXz8/n+JPfOfl+vz9zdwGAJLU0uwEAYweBACAQCAACgQAgEAgAAoEAIDQ1EMzsHDNba2avmNk1zeyl3sxsvZm9aGarzWxVs/sZTWa23Mx6zGzNPvcdYWZPmdm62u3hzexxtAxyrNeZ2abaY7vazL7UzB5HommBYGatkv5F0h9L+pSki8zsU83qp0E+7+4L3L272Y2MshWSzvnIfddIetrd50l6uvb5eLBC+x+rJN1ae2wXuPtjDe5p1DTzDOE0Sa+4+2vuvkfSA5LOa2I/GCZ3XynpnY/cfZ6ke2of3yPp/IY2VSeDHOu40cxA+D1JG/b5fGPtvvHKJT1pZs+b2ZJmN9MAR7v7Fkmq3XY2uZ96W2Zmv629pDhoXx41MxDsAPeN53nUp7v7Z/TBS6S/MrMzm90QRs0dkk6UtEDSFknfam47w9fMQNgoqWufz+dI2tykXurO3TfXbnskPaQPXjKNZ2+Z2WxJqt32NLmfunH3t9y96u4Dku7SQfzYNjMQfiNpnpkdb2aTJf2ZpIeb2E/dmNmhZnbYhx9L+qKkNR//VQe9hyVdWvv4Ukk/amIvdfVh8NV8RQfxY9vWrG/s7v1mtkzSE5JaJS1395ea1U+dHS3pITOTPviZ3+fujze3pdFjZvdLWijpKDPbKOkbkm6W9KCZXS7pd5IuaF6Ho2eQY11oZgv0wUve9ZKWNq3BETKWPwP4EDMVAQQCAUAgEAAEAgFAIBAAhDERCBNkKq+kiXOsE+U4pfF1rGMiECSNmx9ogYlyrBPlOKVxdKxjJRAAjAENnZh01BGtflzXpP3u37qtqplHtu53/4s7j0yN39pbv3yrTs7Vt+458P39u3epbeqhI+rFp1VT9bZj/5/tx6lOzT0nWvbsv06tv7JLbe0HPs6BxM/SJuWOVZXcsVry6T+w/9NX1d5etXZ0DPINysdu6Uv2ckh5bf+2d1Tt3TVkNw2dunxc1yT9+omuoQtr5v3sstT4Hc+0Jzsq1zs398zp+F3imZDUv2h7qr7tqRmp+u2n9KfqD12fexpVusp/yQ+ZtSs1tl6YlipvyR2qKnOSAZX4N+qwl3NhtnN+eS9bbv6noroR/ZM6kbZAAyaCYQfCBN0CDRjXRnKGwBZowDgzkkCYaFugAePeSAKhaAs0M1tiZqvMbNXWbck3ZAA01EgCoWgLNHe/09273b37QP+1CGDsGEkgTJgt0ICJYtjzECbYFmjAhDCiiUm1K9QctFepAfD/NXSm4os7j0zNPly3cEVq/E8/c0WuoYQLzn42Vf/ju86oUydS3+7cPOpBJtUOavK23Hs9U7bnZnHevvR7xbXPVU5Mjf3o8i+k6nfOyf0K3Lj43lT93zzyteLa6W/kpk32zSx/nKxwaBY3AQgEAoBAIAAIBAKAQCAACAQCgEAgAAgEAoBAIAAIBAKAQCAACA3dhr29s8vnXXh13cZ/4W9vL6799I31W/cgSZWzelP17T/PrjgAyq178BZVejYMuRU4ZwgAAoEAIBAIAAKBACAQCAACgQAgEAgAAoEAIBAIAAKBACA0dBv2estMR85Mc86OLeWnIs9cvau4duuCQ1NjT1+/N1X/3nGTUvWWnP7uNuQMWjQJZwgAAoEAIBAIAAKBACAQCAACgQAgEAgAAoEAIBAIAAKBACAQCABCQ9cyVCdLvXPL571fcPazqfF/fNcZxbXZtQn1XvuQWZ/Q15kaWua5hzm7NmHvYbm1Cdcuvre49voXz02NPfeGgVT9jvnTUvVXffOBVP1Nt11cXNuyN/dzn/7qnuLa1r6ysTlDABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEMyT89ZHor2zy+ddeHXdxq+c1VveS/K6CVn1XvsAZKx78BZVejYMueiEMwQAgUAAEEa0/NnM1kvaKakqqd/du0ejKQDNMRr7IXze3d8ehXEANBkvGQCEkQaCS3rSzJ43syWj0RCA5hnpS4bT3X2zmXVKesrM/tfdV+5bUAuKJZI0qePwEX47APU0ojMEd99cu+2R9JCk0w5Qc6e7d7t7d9vU8n0DATTesAPBzA41s8M+/FjSFyWtGa3GADTeSF4yHC3pITP7cJz73P3xUekKQFMMOxDc/TVJfzCKvQBosoZel6HeMusTZq7elRo7c90Eqb7XfciO3bont16lOjl3nQWMH8xDABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEBq6lsGnVdW/aHtxfd/uyanxO55pL67Nrk3o60yV65CeXH1mfUL2mg+f+fuvp+rPX/qzVP19j5yVqt87Y6C4dulZP0mN/cBrp6bqe9fmNu3pn9Gfqj/1918vrl29YU5q7ClT9hbX+uPVojrOEAAEAgFAIBAABAIBQCAQAAQCAUAgEAAEAgFAIBAABAIBQDD33BbdI9He2eXzLry6Yd/v40xfXz7tU5J2HJub5e2W28o8s1X6wKTU0Pqva+9I1WenOmeP1er4nMv2kpXtPdNPPcde9+AtqvRsGPILOEMAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQGroNe3Wqa/sp5dtYT97Wmhq/fXP53O73jsstCKjn/HtJqk4u7z27TXp2bUJ27cPnli1N1b87r/xx/eS5L6fGbmsp3+Jdkrb15bbj3/Bsbqv0v/7qI8W1t67+w9TY1Ur5r2/138uev5whAAgEAoBAIAAIBAKAQCAACAQCgEAgAAgEAoBAIAAIBAKAQCAACA29LsPU2V1+/GXl12WYsj3X20Br/fbA33tYbr//tt5UeUrlmFzvmTUektTxZjVV/4vvfC9Vv+DmK4prZ//83dTYLTsqqfr+199I1W+/5LOp+iP/883i2rfPmJUae8ba8mP99X/foR29m7guA4ByBAKAMGQgmNlyM+sxszX73HeEmT1lZutqt4fXt00AjVByhrBC0jkfue8aSU+7+zxJT9c+B3CQGzIQ3H2lpHc+cvd5ku6pfXyPpPNHuS8ATTDc9xCOdvctklS77Rys0MyWmNkqM1vVX9k1zG8HoBHq/qaiu9/p7t3u3t3WntuuCkBjDTcQ3jKz2ZJUu+0ZvZYANMtwA+FhSZfWPr5U0o9Gpx0AzVTy3473S/qlpE+Y2UYzu1zSzZIWmdk6SYtqnwM4yA25j7O7XzTIX+X2jAYw5jX0ugwDk6VKV/k8+duX5ubIX/WP5XPk3XLz+69dfG+q/qZvX5yqz9g7I3ftAduUe2WYuW6ClFubIEmrr7m9uPZPv7ooNfb7l+XeuM6uTVh5022p+lP+9cri2qNW59ao9M6dWlw78D9lzwGmLgMIBAKAQCAACAQCgEAgAAgEAoBAIAAIBAKAQCAACAQCgNDQqcs2qapDZpVvkvJc5cQ6dpNz/Yvnpuon16kPSVp61k9S9d9/6Y9S9Z889+VU/a5lM1P1menI/3bSU6mxT7rxslS9tDtVfeWmM1P1X170XHHtDyeflhq744T3imurvylbMsAZAoBAIAAIBAKAQCAACAQCgEAgAAgEAoBAIAAIBAKAQCAACAQCgNDQtQyqtEovTCsuf3T5F3LjH5crz5h7Q27r8zdPr1Mjkh547dTcFyS3nG9ryR1ry45Kqj6zVXp2bcIrC1ek6s9fd3aqfv2yk1L1U/5ha3nt3N7U2N2zNhTXbpm0p6iOMwQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBAChsddlcKmlv7x+55zGLrX4ODvml6/BqLfetYen6juS42/rK19rIEktr7+Rqt9+yWcT1bnrJmTXJvxw3hOp+lMXfD1Vf+0xDxXX/t3Dl6TG/unxJxfX7qz8R1EdZwgAAoEAIBAIAAKBACAQCAACgQAgEAgAAoEAIBAIAAKBACAQCABCQxcLDEySKnOqxfU3Lr43Nf71t+bmgmdc9c0HUvU3ffviOnUi9c9ILAiRZJ57mDc8OydVP/2SXP3Km24rrr1y05mpsbPXTciuTXj+ujtS9Sf84C+Law/v9dTYnb8qv97G1sJLPnCGACAMGQhmttzMesxszT73XWdmm8xsde3Pl+rbJoBGKDlDWCHpnAPcf6u7L6j9eWx02wLQDEMGgruvlPROA3oB0GQjeQ9hmZn9tvaSIrdjB4AxabiBcIekEyUtkLRF0rcGKzSzJWa2ysxWVXtzV7cF0FjDCgR3f8vdq+4+IOkuSad9TO2d7t7t7t2tHdnNvAA00rACwcxm7/PpVyStGawWwMFjyBkrZna/pIWSjjKzjZK+IWmhmS2Q5JLWS1paxx4BNMiQgeDuFx3g7rvr0AuAJmOmIoBg7rn50yMx5dgun33NVcX19n75XG1JmvZKHfMtO/RAXbqQJJ140cup+lfvn5+qX7zskVT9o3/Snap/ZfGs4tovL3ouNfa63s5U/V8c80yq/urHvpaqf+2C7xbXfuLu3LqKPbP3Fte+ecM/6/31G4f8heIMAUAgEAAEAgFAIBAABAIBQCAQAAQCAUAgEAAEAgFAIBAAhIZOXZ56dJef9OdXF9dPfyO33fjOY+q3q3xLNfdzGmjNTbvO2HlGJVU/7RdTU/U7Prc7VX/Ek7nx2/rKf5ZvDbrTxoFNmZvbhKftl9NS9ZOSW6X3JnaoX3t5bov3k79zRXHt+rtv0e4tG5i6DKAcgQAgEAgAAoEAIBAIAAKBACAQCAACgQAgEAgAAoEAIBAIAEL9Jv8fwMAh0s751eL6vpmtqfHbN2c7Kjf91T2p+nfnT6lTJ9KUKeXbb0uSW3uqvlrJPS1mrM2treidW772oeOE91Jjd8/akKr/6fEnp+o7f5Vbo7Jndvl6nMzaBEl6adntxbWnPbK1qI4zBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAKGh12Uws62S3jjAXx0l6e2GNdJcE+VYJ8pxSgfHsR7r7jOHKmpoIAzahNkqd+9udh+NMFGOdaIcpzS+jpWXDAACgQAgjJVAuLPZDTTQRDnWiXKc0jg61jHxHgKAsWGsnCEAGAMIBACBQAAQCAQAgUAAEP4PSqOu3T7hUDYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23c0015c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.feature_selection.SelectKBest\n",
    "\n",
    "[Documentação](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest)\n",
    "\n",
    "Destina-se à seleção de features de acordo às maiores k pontuações. Utiliza além disso uma função para pontuação que para problemas de classificação é a f_classif. O retorno é um par de matrizes com scores e valores ou único array de scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.853e+03 7.318e-01 9.711e-01 4.111e+02 1.367e-01 6.056e-02 2.239e+03\n",
      " 4.234e+00 8.555e+02 6.235e+01 7.668e+02 2.194e+03 1.249e+02 6.424e+01\n",
      " 7.025e+02 8.588e+02 6.756e+00 7.775e+02]\n",
      "[[0.973 0.568 0.89  0.994]\n",
      " [1.668 3.475 0.568 0.205]\n",
      " [0.445 1.22  0.942 1.562]\n",
      " [0.381 2.033 1.015 1.715]\n",
      " [1.31  1.088 0.968 0.043]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=f_classif, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "\n",
    "A Recursive Feature Elimination (ou RFE) consiste na remoção de maneira recursiva de atributos e construção de modelo com os que permanecem. De maniera geral, utiliza a precisão de um modelo para identificar quais atributos são mais relevantes para a predição.\n",
    "\n",
    "#### sklearn.feature_selection.RFE\n",
    "\n",
    "[Documentação](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [ True False False False False False  True False False False False False\n",
      " False False  True False False False]\n",
      "Feature Ranking: [ 1 16 15  6 13 14  1 12  9  8 10  3  2 11  1  7  4  5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "\n",
    "Consiste em um procedimento estático que utiliza transformação ortogonal de algébra linear, que converte um conjunto de observações de variáveis que estejam correlacionadas em valores linearmente não correlacionados, chamados de componentes principais. É aplicado para compressão e simplificação de dados, buscando facilitar a a visualização.Entretanto, não é recomendado em casos de dados ruidosos (com falta de registro, etc). Conforme exemplo abaixo, observa-se que os três componentes principais possuem pouca semelhança com os originais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.21387623 0.14724111 0.12447848]\n",
      "[[ 2.26460032e-01 -1.15283788e-02 -1.25404520e-03  1.16756875e-01\n",
      "   1.44353846e-02  2.77363229e-03  4.44841446e-01  3.80707533e-03\n",
      "   4.75274631e-01 -2.15403163e-01  1.75895845e-01  3.36484206e-01\n",
      "   1.65976887e-01  3.44711211e-01  2.03284781e-01  3.50284058e-01\n",
      "   8.49859170e-02  5.26202293e-02]\n",
      " [ 3.36050072e-01 -1.15689931e-03 -1.81344789e-03  3.36856995e-01\n",
      "   8.48468631e-03 -1.38600743e-03  2.15798213e-01 -2.92793122e-03\n",
      "  -8.81029798e-02  5.24511890e-01  3.50327632e-01  9.99204979e-02\n",
      "  -2.09037436e-01 -3.89981256e-01  3.14388720e-01 -1.21561242e-01\n",
      "  -2.71474917e-02 -3.48841354e-02]\n",
      " [-1.30719003e-03 -7.00213814e-01 -8.05963274e-02  4.64313739e-04\n",
      "  -7.02992938e-01  6.98820708e-02  6.71838751e-03  6.32527873e-02\n",
      "  -2.63043337e-03  7.28472023e-03  7.65209391e-04  5.54086100e-04\n",
      "   1.72030515e-03 -5.76377168e-04  8.31231631e-04  2.83888010e-03\n",
      "  -2.27799334e-04  1.15063845e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with PCA\n",
    "import numpy\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Além dos métodos apresentados anteriormente, é possível utilizar árvore de decisão (Random Forest e Extra Trees) para estimar a importância das features. Abaixo tem um exemplo de aplicação de ExtraTrees, em que se constrói um modelo  e a partir dele é calculada uma importância para cada feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09599041 0.04638616 0.03429688 0.04343944 0.04082472 0.03534582\n",
      " 0.09807981 0.03475428 0.05594701 0.07197435 0.05524765 0.08067933\n",
      " 0.04340342 0.0466097  0.05566365 0.0481973  0.04293166 0.07022841]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
